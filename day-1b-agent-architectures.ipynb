{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##### Copyright 2025 Google LLC.","metadata":{}},{"cell_type":"code","source":"# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T21:57:40.307674Z","iopub.execute_input":"2025-11-10T21:57:40.307986Z","iopub.status.idle":"2025-11-10T21:57:40.313551Z","shell.execute_reply.started":"2025-11-10T21:57:40.307935Z","shell.execute_reply":"2025-11-10T21:57:40.312426Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# üöÄ Multi-Agent Systems & Workflow Patterns\n\n**Welcome to the Kaggle 5-day Agents course!**\n\nIn the previous notebook, you built a **single agent** that could take action. Now, you'll learn how to scale up by building **agent teams**.\n\nJust like a team of people, you can create specialized agents that collaborate to solve complex problems. This is called a **multi-agent system**, and it's one of the most powerful concepts in AI agent development.\n\nIn this notebook, you'll:\n\n- ‚úÖ Learn when to use multi-agent systems in [Agent Development Kit (ADK)](https://google.github.io/adk-docs/)\n- ‚úÖ Build your first system using an LLM as a \"manager\"\n- ‚úÖ Learn three core workflow patterns (Sequential, Parallel, and Loop) to coordinate your agent teams\n\n## ‚ÄºÔ∏è Please Read\n\n> ‚ùå **‚ÑπÔ∏è Note: No submission required!**\n> This notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n\n> ‚è∏Ô∏è **Note:**  When you first start the notebook via running a cell you might see a banner in the notebook header that reads **\"Waiting for the next available notebook\"**. The queue should drop rapidly; however, during peak bursts you might have to wait a few minutes.\n\n> ‚ùå **Note:** Avoid using the **Run all** cells command as this can trigger a QPM limit resulting in 429 errors when calling the backing model. Suggested flow is to run each cell in order - one at a time. [See FAQ on 429 errors for more information.](https://www.kaggle.com/code/kaggle5daysofai/day-0-troubleshooting-and-faqs)\n\n**For help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server.**","metadata":{}},{"cell_type":"markdown","source":"## üìñ Get started with Kaggle Notebooks\n\nIf this is your first time using Kaggle Notebooks, welcome! You can learn more about using Kaggle Notebooks [in the documentation](https://www.kaggle.com/docs/notebooks).\n\nHere's how to get started:\n\n**1. Verify Your Account (Required)**\n\nTo use the Kaggle Notebooks in this course, you'll need to verify your account with a phone number.\n\nYou can do this in your [Kaggle settings](https://www.kaggle.com/settings).\n\n**2. Make Your Own Copy**\n\nTo run any code in this notebook, you first need your own editable copy.\n\nClick the `Copy and Edit` button in the top-right corner.\n\n![Copy and Edit button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_1.png)\n\nThis creates a private copy of the notebook just for you.\n\n**3. Run Code Cells**\n\nOnce you have your copy, you can run code.\n\nClick the ‚ñ∂Ô∏è Run button next to any code cell to execute it.\n\n![Run cell button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_2.png)\n\nRun the cells in order from top to bottom.\n\n**4. If You Get Stuck**\n\nTo restart: Select `Factory reset` from the `Run` menu.\n\nFor help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server.","metadata":{}},{"cell_type":"markdown","source":"## ‚öôÔ∏è Section 1: Setup\n\n### 1.1: Install dependencies\n\nThe Kaggle Notebooks environment includes a pre-installed version of the [google-adk](https://google.github.io/adk-docs/) library for Python and its required dependencies, so you don't need to install additional packages in this notebook.\n\nTo install and use ADK in your own Python development environment outside of this course, you can do so by running:\n\n```\npip install google-adk\n```","metadata":{}},{"cell_type":"markdown","source":"### 1.2: Configure your Gemini API Key\n\nThis notebook uses the [Gemini API](https://ai.google.dev/gemini-api/docs), which requires authentication.\n\n**1. Get your API key**\n\nIf you don't have one already, create an [API key in Google AI Studio](https://aistudio.google.com/app/api-keys).\n\n**2. Add the key to Kaggle Secrets**\n\nNext, you will need to add your API key to your Kaggle Notebook as a Kaggle User Secret.\n\n1. In the top menu bar of the notebook editor, select `Add-ons` then `Secrets`.\n2. Create a new secret with the label `GOOGLE_API_KEY`.\n3. Paste your API key into the \"Value\" field and click \"Save\".\n4. Ensure that the checkbox next to `GOOGLE_API_KEY` is selected so that the secret is attached to the notebook.\n\n**3. Authenticate in the notebook**\n\nRun the cell below to complete authentication.","metadata":{}},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    print(\"‚úÖ Gemini API key setup complete.\")\nexcept Exception as e:\n    print(\n        f\"üîë Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\"\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T00:54:09.261432Z","iopub.execute_input":"2025-11-11T00:54:09.261877Z","iopub.status.idle":"2025-11-11T00:54:09.334071Z","shell.execute_reply.started":"2025-11-11T00:54:09.261836Z","shell.execute_reply":"2025-11-11T00:54:09.333067Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Gemini API key setup complete.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"### 1.3: Import ADK components\n\nNow, import the specific components you'll need from the Agent Development Kit and the Generative AI library. This keeps your code organized and ensures we have access to the necessary building blocks.","metadata":{}},{"cell_type":"code","source":"from google.adk.agents import Agent, SequentialAgent, ParallelAgent, LoopAgent\nfrom google.adk.models.google_llm import Gemini\nfrom google.adk.runners import InMemoryRunner\nfrom google.adk.tools import AgentTool, FunctionTool, google_search\nfrom google.genai import types\n\nprint(\"‚úÖ ADK components imported successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T00:30:01.611006Z","iopub.execute_input":"2025-11-11T00:30:01.611383Z","iopub.status.idle":"2025-11-11T00:30:50.094712Z","shell.execute_reply.started":"2025-11-11T00:30:01.611356Z","shell.execute_reply":"2025-11-11T00:30:50.093837Z"}},"outputs":[{"name":"stdout","text":"‚úÖ ADK components imported successfully.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### 1.4: Configure Retry Options\n\nWhen working with LLMs, you may encounter transient errors like rate limits or temporary service unavailability. Retry options automatically handle these failures by retrying the request with exponential backoff.","metadata":{}},{"cell_type":"code","source":"retry_config=types.HttpRetryOptions(\n    attempts=5,  # Maximum retry attempts\n    exp_base=7,  # Delay multiplier\n    initial_delay=1,\n    http_status_codes=[429, 500, 503, 504], # Retry on these HTTP errors\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T00:54:05.771822Z","iopub.execute_input":"2025-11-11T00:54:05.772149Z","iopub.status.idle":"2025-11-11T00:54:05.778058Z","shell.execute_reply.started":"2025-11-11T00:54:05.772127Z","shell.execute_reply":"2025-11-11T00:54:05.776970Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"---\n## ü§î Section 2: Why Multi-Agent Systems? + Your First Multi-Agent","metadata":{}},{"cell_type":"markdown","source":"**The Problem: The \"Do-It-All\" Agent**\n\nSingle agents can do a lot. But what happens when the task gets complex? A single \"monolithic\" agent that tries to do research, writing, editing, and fact-checking all at once becomes a problem. Its instruction prompt gets long and confusing. It's hard to debug (which part failed?), difficult to maintain, and often produces unreliable results.\n\n**The Solution: A Team of Specialists**\n\nInstead of one \"do-it-all\" agent, we can build a **multi-agent system**. This is a team of simple, specialized agents that collaborate, just like a real-world team. Each agent has one clear job (e.g., one agent *only* does research, another *only* writes). This makes them easier to build, easier to test, and much more powerful and reliable when working together.\n\nTo learn more, check out the documentation related to [LLM agents in ADK](https://google.github.io/adk-docs/agents/llm-agents/).\n\n**Architecture: Single Agent vs Multi-Agent Team**\n\n<!--\n```mermaid\ngraph TD\n    subgraph Single[\"‚ùå Monolithic Agent\"]\n        A[\"One Agent Does Everything\"]\n    end\n\n    subgraph Multi[\"‚úÖ Multi-Agent Team\"]\n        B[\"Root Coordinator\"] -- > C[\"Research Specialist\"]\n        B -- > E[\"Summary Specialist\"]\n\n        C -- >|findings| F[\"Shared State\"]\n        E -- >|summary| F\n    end\n\n    style A fill:#ffcccc\n    style B fill:#ccffcc\n    style F fill:#ffffcc\n```\n-->","metadata":{}},{"cell_type":"markdown","source":"<img width=\"800\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/multi-agent-team.png\" alt=\"Multi-agent Team\" />","metadata":{}},{"cell_type":"markdown","source":"### 2.1 Example: Research & Summarization System\n\nLet's build a system with two specialized agents:\n\n1. **Research Agent** - Searches for information using Google Search\n2. **Summarizer Agent** - Creates concise summaries from research findings","metadata":{}},{"cell_type":"code","source":"# Research Agent: Its job is to use the google_search tool and present findings.\nresearch_agent = Agent(\n    name=\"ResearchAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a specialized research agent. Your only job is to use the\n    google_search tool to find 2-3 pieces of relevant information on the given topic and present the findings with citations.\"\"\",\n    tools=[google_search],\n    output_key=\"research_findings\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ research_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T22:49:56.930178Z","iopub.execute_input":"2025-11-10T22:49:56.930576Z","iopub.status.idle":"2025-11-10T22:49:56.937815Z","shell.execute_reply.started":"2025-11-10T22:49:56.930549Z","shell.execute_reply":"2025-11-10T22:49:56.937034Z"}},"outputs":[{"name":"stdout","text":"‚úÖ research_agent created.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Summarizer Agent: Its job is to summarize the text it receives.\nsummarizer_agent = Agent(\n    name=\"SummarizerAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # The instruction is modified to request a bulleted list for a clear output format.\n    instruction=\"\"\"Read the provided research findings: {research_findings}\nCreate a concise summary as a bulleted list with 3-5 key points.\"\"\",\n    output_key=\"final_summary\",\n)\n\nprint(\"‚úÖ summarizer_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T22:49:58.615133Z","iopub.execute_input":"2025-11-10T22:49:58.615465Z","iopub.status.idle":"2025-11-10T22:49:58.621224Z","shell.execute_reply.started":"2025-11-10T22:49:58.615440Z","shell.execute_reply":"2025-11-10T22:49:58.620295Z"}},"outputs":[{"name":"stdout","text":"‚úÖ summarizer_agent created.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"Refer to the ADK documentation for more information on [guiding agents with clear and specific instructions](https://google.github.io/adk-docs/agents/llm-agents/).\n\nThen we bring the agents together under a **root agent, or coordinator**:","metadata":{}},{"cell_type":"code","source":"# Root Coordinator: Orchestrates the workflow by calling the sub-agents as tools.\nroot_agent = Agent(\n    name=\"ResearchCoordinator\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # This instruction tells the root agent HOW to use its tools (which are the other agents).\n    instruction=\"\"\"You are a research coordinator. Your goal is to answer the user's query by orchestrating a workflow.\n1. First, you MUST call the `ResearchAgent` tool to find relevant information on the topic provided by the user.\n2. Next, after receiving the research findings, you MUST call the `SummarizerAgent` tool to create a concise summary.\n3. Finally, present the final summary clearly to the user as your response.\"\"\",\n    # We wrap the sub-agents in `AgentTool` to make them callable tools for the root agent.\n    tools=[AgentTool(research_agent), AgentTool(summarizer_agent)],\n)\n\nprint(\"‚úÖ root_agent created.\")","metadata":{"id":"PKthuzRkBtHD","outputId":"dee6d4cc-17b4-4430-8454-d56096fbe360","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T22:57:56.094686Z","iopub.execute_input":"2025-11-10T22:57:56.095003Z","iopub.status.idle":"2025-11-10T22:57:56.100703Z","shell.execute_reply.started":"2025-11-10T22:57:56.094983Z","shell.execute_reply":"2025-11-10T22:57:56.099907Z"}},"outputs":[{"name":"stdout","text":"‚úÖ root_agent created.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"### NOTE:\nHere we're using `AgentTool` to wrap the sub-agents to make them _callable tools_ for the root agent. We'll explore `AgentTool` in-detail on Day 2.\n\nLet's run the agent and ask it about a topic:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"What are the latest advancements in quantum computing and what do they mean for AI?\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T00:54:16.000082Z","iopub.execute_input":"2025-11-11T00:54:16.000425Z","iopub.status.idle":"2025-11-11T00:54:21.966434Z","shell.execute_reply.started":"2025-11-11T00:54:16.000398Z","shell.execute_reply":"2025-11-11T00:54:21.965439Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > What are the latest advancements in quantum computing and what do they mean for AI?\n","output_type":"stream"},{"name":"stderr","text":"ERROR:asyncio:Task exception was never retrieved\nfuture: <Task finished name='Task-16' coro=<BaseApiClient.aclose() done, defined at /usr/local/lib/python3.11/dist-packages/google/genai/_api_client.py:1812> exception=AttributeError(\"'BaseApiClient' object has no attribute '_async_httpx_client'\")>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/google/genai/_api_client.py\", line 1815, in aclose\n    await self._async_httpx_client.aclose()\n          ^^^^^^^^^^^^^^^^^^^^^^^^\nAttributeError: 'BaseApiClient' object has no attribute '_async_httpx_client'\nERROR:asyncio:Task exception was never retrieved\nfuture: <Task finished name='Task-17' coro=<BaseApiClient.aclose() done, defined at /usr/local/lib/python3.11/dist-packages/google/genai/_api_client.py:1812> exception=AttributeError(\"'BaseApiClient' object has no attribute '_async_httpx_client'\")>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/google/genai/_api_client.py\", line 1815, in aclose\n    await self._async_httpx_client.aclose()\n          ^^^^^^^^^^^^^^^^^^^^^^^^\nAttributeError: 'BaseApiClient' object has no attribute '_async_httpx_client'\nERROR:asyncio:Task exception was never retrieved\nfuture: <Task finished name='Task-18' coro=<BaseApiClient.aclose() done, defined at /usr/local/lib/python3.11/dist-packages/google/genai/_api_client.py:1812> exception=AttributeError(\"'BaseApiClient' object has no attribute '_async_httpx_client'\")>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/google/genai/_api_client.py\", line 1815, in aclose\n    await self._async_httpx_client.aclose()\n          ^^^^^^^^^^^^^^^^^^^^^^^^\nAttributeError: 'BaseApiClient' object has no attribute '_async_httpx_client'\n","output_type":"stream"},{"name":"stdout","text":"HealthResearcher > **Quantum Echoes Algorithm Breakthrough:** Google Quantum AI's October 2025 achievement of the \"Quantum Echoes\" algorithm is a significant advance, demonstrating a quantum computer outperforming classical supercomputers by 13,000 times in a physics simulation. This development is part of rapid progress, with experts predicting practical quantum AI applications within 5-10 years.\n\n**Impact on AI:** This breakthrough and ongoing advancements suggest quantum computing will revolutionize AI by enabling unprecedented speed and sophistication in information processing and pattern recognition. This could lead to accelerated drug discovery, more accurate climate modeling, and enhanced financial decision-making.\n\n**Timeline:** While widespread commercial adoption is still a decade away, initial practical applications are anticipated within the next 5-10 years. More optimistic projections suggest significant progress by 2030, particularly with improvements in qubit stability and count.\nFinanceResearcher > Here are three key trends in quantum computing advancements and their implications for AI:\n\n1.  **Quantum Machine Learning (QML):** This trend focuses on using quantum algorithms to enhance classical machine learning.\n    *   **Market Implications:** QML could lead to AI models that learn and adapt exponentially faster. This is crucial for handling massive datasets and complex problems in areas like drug discovery, materials science, and natural language processing, potentially creating new market opportunities.\n    *   **Future Outlook:** Expect more sophisticated QML algorithms and hybrid quantum-classical systems that leverage the strengths of both. Breakthroughs are anticipated by the end of the decade.\n\n2.  **Enhanced Optimization and Problem-Solving:** Quantum computing excels at solving optimization problems and complex simulations that are intractable for classical computers.\n    *   **Market Implications:** This will revolutionize fields like finance (risk assessment, portfolio optimization), logistics (supply chain efficiency), and scientific research (molecular modeling, drug discovery) by enabling real-time, large-scale simulations and faster decision-making.\n    *   **Future Outlook:** As quantum hardware matures, these capabilities will become more accessible, driving innovation in various industries and potentially leading to significant market growth.\n\n3.  **Energy Efficiency and Sustainability:** Quantum AI models may require significantly fewer parameters and less computational power than classical AI models.\n    *   **Market Implications:** This could address one of the major challenges of current AI: its high energy and computational demands. A more sustainable AI could lead to wider adoption and reduced operational costs, creating a more environmentally friendly tech landscape.\n    *   **Future Outlook:** Continued advancements in quantum hardware and algorithms are expected to yield more energy-efficient AI solutions, making them more accessible and sustainable in the long term.\nTechResearcher > **Key Developments in Quantum Computing and AI:**\n\n1.  **Quantum Error Correction:** Significant progress is being made in developing error-corrected qubits and logical qubits. This is crucial for building reliable, large-scale quantum computers capable of complex computations. Google Quantum AI has demonstrated the practical application of quantum error correction, showing that increasing qubit numbers can reduce errors.\n2.  **Quantum Advantage Algorithms:** Researchers are developing algorithms that demonstrate \"quantum advantage,\" where quantum computers outperform classical computers for specific tasks. Google's \"Quantum Echoes\" algorithm, run on their Willow quantum chip, has shown verifiable quantum advantage, running 13,000 times faster than the best classical algorithms for certain molecular structure computations.\n3.  **Hybrid Quantum-Classical AI:** The integration of quantum computing with classical AI is accelerating. This synergy allows AI to tackle problems intractable for classical computers, while AI can improve the reliability and performance of quantum systems. Companies are developing hybrid models for machine learning and exploring quantum-enhanced natural language processing.\n\n**Main Companies Involved:**\n\n*   **IBM:** A leader in developing superconducting qubits and scalable quantum systems, offering cloud-based quantum platforms.\n*   **Google Quantum AI:** Focused on large-scale architecture, quantum algorithms for AI/ML, and demonstrated quantum advantage with their Sycamore and Willow processors.\n*   **Microsoft (Azure Quantum):** Investing in hybrid quantum-classical AI research and developing topological qubits, with a cloud platform offering access to various quantum hardware.\n*   **Quantinuum:** Working on Generative Quantum AI and developing powerful quantum computers, exploring hybrid quantum-classical computation.\n\n**Potential Impact on AI:**\n\nQuantum computing promises to revolutionize AI by enabling faster and more efficient training of models, enhanced optimization capabilities, and superior data processing. This could lead to breakthroughs in areas like drug discovery, materials science, personalized medicine, and complex optimization problems, significantly expanding AI's capabilities beyond current limitations.\nAggregatorAgent > **Executive Summary: Quantum Computing's Transformative Impact on AI**\n\nRecent breakthroughs in quantum computing are poised to revolutionize Artificial Intelligence, promising exponential gains in processing power, problem-solving, and efficiency. Key advancements include robust quantum error correction, enabling more reliable quantum hardware, and the development of \"quantum advantage\" algorithms. Google's \"Quantum Echoes\" algorithm, for instance, demonstrated a 13,000x speedup over classical supercomputers for specific physics simulations, showcasing quantum computers' superior capability for complex tasks.\n\nThe convergence of quantum and classical computing through hybrid AI models is a significant trend, allowing AI to tackle previously intractable problems. This synergy will drive AI's capabilities in areas such as accelerated drug discovery, advanced materials science, enhanced financial modeling (risk assessment, portfolio optimization), and more efficient logistics. While widespread commercial adoption is still a decade away, initial practical applications are anticipated within the next 5-10 years, with significant progress expected by 2030. Furthermore, quantum AI models hold the potential for greater energy efficiency, addressing a critical challenge in current AI development. Major players like IBM, Google, Microsoft, and Quantinuum are actively pushing these advancements.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"You've just built your first multi-agent system! You used a single \"coordinator\" agent to manage the workflow, which is a powerful and flexible pattern.\n\n‚ÄºÔ∏è However, **relying on an LLM's instructions to control the order can sometimes be unpredictable.** Next, we'll explore a different pattern that gives you guaranteed, step-by-step execution.","metadata":{}},{"cell_type":"markdown","source":"---\n\n## üö• Section 3: Sequential Workflows - The Assembly Line\n\n**The Problem: Unpredictable Order**\n\nThe previous multi-agent system worked, but it relied on a **detailed instruction prompt** to force the LLM to run steps in order. This can be unreliable. A complex LLM might decide to skip a step, run them in the wrong order, or get \"stuck,\" making the process unpredictable.\n\n**The Solution: A Fixed Pipeline**\n\nWhen you need tasks to happen in a **guaranteed, specific order**, you can use a `SequentialAgent`. This agent acts like an assembly line, running each sub-agent in the exact order you list them. The output of one agent automatically becomes the input for the next, creating a predictable and reliable workflow.\n\n**Use Sequential when:** Order matters, you need a linear pipeline, or each step builds on the previous one.\n\nTo learn more, check out the documentation related to [sequential agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/).\n\n**Architecture: Blog Post Creation Pipeline**\n\n<!--\n```mermaid\ngraph LR\n    A[\"User Input: Blog about AI\"] -- > B[\"Outline Agent\"]\n    B -- >|blog_outline| C[\"Writer Agent\"]\n    C -- >|blog_draft| D[\"Editor Agent\"]\n    D -- >|final_blog| E[\"Output\"]\n\n    style B fill:#ffcccc\n    style C fill:#ccffcc\n    style D fill:#ccccff\n```\n-->","metadata":{"id":"h6Bcds7EBtHE"}},{"cell_type":"markdown","source":"<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/sequential-agent.png\" alt=\"Sequential Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 3.1 Example: Blog Post Creation with Sequential Agents\n\nLet's build a system with three specialized agents:\n\n1. **Outline Agent** - Creates a blog outline for a given topic\n2. **Writer Agent** - Writes a blog post\n3. **Editor Agent** - Edits a blog post draft for clarity and structure","metadata":{"id":"h6Bcds7EBtHE"}},{"cell_type":"code","source":"# Outline Agent: Creates the initial blog post outline.\noutline_agent = Agent(\n    name=\"OutlineAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Create a blog outline for the given topic with:\n    1. A catchy headline\n    2. An introduction hook\n    3. 3-5 main sections with 2-3 bullet points for each\n    4. A concluding thought\"\"\",\n    output_key=\"blog_outline\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ outline_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T23:24:57.554583Z","iopub.execute_input":"2025-11-10T23:24:57.555126Z","iopub.status.idle":"2025-11-10T23:24:57.561743Z","shell.execute_reply.started":"2025-11-10T23:24:57.555086Z","shell.execute_reply":"2025-11-10T23:24:57.560697Z"}},"outputs":[{"name":"stdout","text":"‚úÖ outline_agent created.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Writer Agent: Writes the full blog post based on the outline from the previous agent.\nwriter_agent = Agent(\n    name=\"WriterAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # The `{blog_outline}` placeholder automatically injects the state value from the previous agent's output.\n    instruction=\"\"\"Following this outline strictly: {blog_outline}\n    Write a brief, 200 to 300-word blog post with an engaging and informative tone.\"\"\",\n    output_key=\"blog_draft\",  # The result of this agent will be stored with this key.\n)\n\nprint(\"‚úÖ writer_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T23:25:15.895982Z","iopub.execute_input":"2025-11-10T23:25:15.896321Z","iopub.status.idle":"2025-11-10T23:25:15.901889Z","shell.execute_reply.started":"2025-11-10T23:25:15.896290Z","shell.execute_reply":"2025-11-10T23:25:15.900835Z"}},"outputs":[{"name":"stdout","text":"‚úÖ writer_agent created.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Editor Agent: Edits and polishes the draft from the writer agent.\neditor_agent = Agent(\n    name=\"EditorAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # This agent receives the `{blog_draft}` from the writer agent's output.\n    instruction=\"\"\"Edit this draft: {blog_draft}\n    Your task is to polish the text by fixing any grammatical errors, improving the flow and sentence structure, and enhancing overall clarity.\"\"\",\n    output_key=\"final_blog\",  # This is the final output of the entire pipeline.\n)\n\nprint(\"‚úÖ editor_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T23:25:47.004353Z","iopub.execute_input":"2025-11-10T23:25:47.005106Z","iopub.status.idle":"2025-11-10T23:25:47.010656Z","shell.execute_reply.started":"2025-11-10T23:25:47.005076Z","shell.execute_reply":"2025-11-10T23:25:47.009629Z"}},"outputs":[{"name":"stdout","text":"‚úÖ editor_agent created.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"Then we bring the agents together under a sequential agent, which runs the agents in the order that they are listed:","metadata":{}},{"cell_type":"code","source":"root_agent = SequentialAgent(\n    name=\"BlogPipeline\",\n    sub_agents=[outline_agent, writer_agent, editor_agent],\n)\n\nprint(\"‚úÖ Sequential Agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T23:25:59.913187Z","iopub.execute_input":"2025-11-10T23:25:59.913474Z","iopub.status.idle":"2025-11-10T23:25:59.918919Z","shell.execute_reply.started":"2025-11-10T23:25:59.913454Z","shell.execute_reply":"2025-11-10T23:25:59.918006Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Sequential Agent created.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"Let's run the agent and give it a topic to write a blog post about:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Write a blog post about the benefits of multi-agent systems for software developers\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T23:26:04.578857Z","iopub.execute_input":"2025-11-10T23:26:04.579840Z","iopub.status.idle":"2025-11-10T23:26:10.277951Z","shell.execute_reply.started":"2025-11-10T23:26:04.579806Z","shell.execute_reply":"2025-11-10T23:26:10.276919Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Write a blog post about the benefits of multi-agent systems for software developers\nOutlineAgent > ## Blog Outline: Multi-Agent Systems - Your Secret Weapon for Smarter Software\n\n**Introduction Hook:**\n\nTired of wrestling with monolithic codebases that are complex, brittle, and a nightmare to scale? Imagine a software architecture where independent, intelligent \"agents\" collaborate to solve problems, adapt to change, and optimize performance. This isn't science fiction; it's the power of Multi-Agent Systems (MAS), and they're poised to revolutionize how we build software.\n\n---\n\n**Section 1: The Power of Decomposition - Breaking Down Complexity**\n\n*   **Modular and Independent Units:** MAS breaks down large, intricate problems into smaller, manageable tasks handled by individual agents. This makes code easier to understand, develop, and debug.\n*   **Specialized Expertise:** Each agent can be designed with specific skills and knowledge, leading to more efficient and optimized solutions for particular sub-problems. Think of them as tiny, expert teams working under one roof.\n*   **Enhanced Maintainability:** When you need to update or fix a specific functionality, you only need to focus on the relevant agent, minimizing the risk of introducing unintended side effects elsewhere in the system.\n\n**Section 2: Adaptability and Resilience - Building Software That Thrives**\n\n*   **Dynamic Problem Solving:** Agents can communicate, negotiate, and coordinate their actions to respond to changing environments or unexpected situations in real-time. This makes your software more robust and less prone to failure.\n*   **Fault Tolerance:** If one agent fails, the system can often continue operating by reallocating tasks or using alternative agents, creating a more resilient architecture.\n*   **Scalability on Demand:** MAS naturally lends itself to scaling. You can easily add more agents to handle increased load or introduce new functionalities without a complete system overhaul.\n\n**Section 3: Intelligence and Optimization - Driving Smarter Software**\n\n*   **Distributed Decision-Making:** Agents can make localized decisions based on their own perceptions and goals, leading to more efficient and responsive systems.\n*   **Emergent Behavior:** Complex and intelligent behavior can emerge from the interactions of simple agents, often leading to solutions that a single monolithic program might not achieve.\n*   **Continuous Learning and Improvement:** Agents can be designed to learn from their experiences and adapt their strategies over time, leading to continuously improving performance and effectiveness.\n\n---\n\n**Concluding Thought:**\n\nFor software developers, embracing Multi-Agent Systems isn't just about adopting a new paradigm; it's about unlocking a more agile, intelligent, and robust future for your applications. By leveraging the collective power of independent agents, you can build software that is not only easier to manage but also more capable of tackling the complex challenges of tomorrow. Are you ready to build smarter?\nWriterAgent > ## Multi-Agent Systems: Your Secret Weapon for Smarter Software\n\nAre you tired of wrestling with monolithic codebases that are complex, brittle, and a nightmare to scale? Imagine a software architecture where independent, intelligent \"agents\" collaborate to solve problems, adapt to change, and optimize performance. This isn't science fiction; it's the power of Multi-Agent Systems (MAS), and they're poised to revolutionize how we build software.\n\nMAS tackles complexity by **breaking down large problems into smaller, manageable tasks** handled by individual agents. Each agent can be designed with specialized expertise, making them tiny, expert teams working together. This modularity dramatically enhances maintainability; fixing a bug or updating a feature means focusing on a single agent, minimizing unintended side effects.\n\nBeyond simplification, MAS builds software that **thrives in dynamic environments**. Agents can communicate, negotiate, and coordinate actions in real-time, making your system more robust and adaptable. If one agent fails, the system can often continue operating by reallocating tasks, ensuring fault tolerance. Plus, MAS naturally scales ‚Äì simply add more agents to handle increased load or introduce new functionalities without a complete overhaul.\n\nFinally, MAS drives **intelligent optimization**. Distributed decision-making leads to more efficient and responsive systems. Complex behaviors can emerge from the interactions of simple agents, often achieving outcomes a single program wouldn't. These agents can even learn from experience, continuously improving performance over time.\n\nFor software developers, embracing MAS means unlocking a more agile, intelligent, and robust future for your applications. Are you ready to build smarter?\nEditorAgent > ## Multi-Agent Systems: Your Secret Weapon for Smarter Software\n\nAre you tired of wrestling with monolithic codebases that are complex, brittle, and a nightmare to scale? Imagine a software architecture where independent, intelligent \"agents\" collaborate to solve problems, adapt to change, and optimize performance. This isn't science fiction; it's the power of Multi-Agent Systems (MAS), and they're poised to revolutionize how we build software.\n\nMAS tackles complexity by **breaking down large, intricate problems into smaller, manageable tasks** handled by individual agents. Each agent can be designed with specialized expertise, making them akin to tiny, expert teams working together. This modularity dramatically enhances maintainability; fixing a bug or updating a feature means focusing on a single agent, minimizing the risk of unintended side effects elsewhere in the system.\n\nBeyond simplification, MAS builds software that **thrives in dynamic environments**. Agents can communicate, negotiate, and coordinate actions in real-time, making your system more robust and adaptable. If one agent fails, the system can often continue operating by reallocating tasks or utilizing alternative agents, ensuring fault tolerance. Moreover, MAS naturally scales ‚Äì you can simply add more agents to handle increased load or introduce new functionalities without requiring a complete system overhaul.\n\nFinally, MAS drives **intelligent optimization**. Distributed decision-making leads to more efficient and responsive systems. Complex behaviors can emerge from the interactions of simple agents, often achieving outcomes that a single, monolithic program might struggle to attain. These agents can even be designed to learn from their experiences, continuously improving performance and effectiveness over time.\n\nFor software developers, embracing MAS means unlocking a more agile, intelligent, and robust future for your applications. By leveraging the collective power of independent agents, you can build software that is not only easier to manage but also more capable of tackling the complex challenges of tomorrow. Are you ready to build smarter?\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"üëè Great job! You've now created a reliable \"assembly line\" using a sequential agent, where each step runs in a predictable order.\n\n**This is perfect for tasks that build on each other, but it's slow if the tasks are independent.** Next, we'll look at how to run multiple agents at the same time to speed up your workflow.","metadata":{}},{"cell_type":"markdown","source":"---\n## üõ£Ô∏è Section 4: Parallel Workflows - Independent Researchers\n\n**The Problem: The Bottleneck**\n\nThe previous sequential agent is great, but it's an assembly line. Each step must wait for the previous one to finish. What if you have several tasks that are **not dependent** on each other? For example, researching three *different* topics. Running them in sequence would be slow and inefficient, creating a bottleneck where each task waits unnecessarily.\n\n**The Solution: Concurrent Execution**\n\nWhen you have independent tasks, you can run them all at the same time using a `ParallelAgent`. This agent executes all of its sub-agents concurrently, dramatically speeding up the workflow. Once all parallel tasks are complete, you can then pass their combined results to a final 'aggregator' step.\n\n**Use Parallel when:** Tasks are independent, speed matters, and you can execute concurrently.\n\nTo learn more, check out the documentation related to [parallel agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/).\n\n**Architecture: Multi-Topic Research**\n\n<!--\n```mermaid\ngraph TD\n    A[\"User Request: Research 3 topics\"] -- > B[\"Parallel Execution\"]\n    B -- > C[\"Tech Researcher\"]\n    B -- > D[\"Health Researcher\"]\n    B -- > E[\"Finance Researcher\"]\n\n    C -- > F[\"Aggregator\"]\n    D -- > F\n    E -- > F\n    F -- > G[\"Combined Report\"]\n\n    style B fill:#ffffcc\n    style F fill:#ffccff\n```\n-->","metadata":{"id":"U37FxKxDBtHE"}},{"cell_type":"markdown","source":"<img width=\"600\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/parallel-agent.png\" alt=\"Parallel Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 4.1 Example: Parallel Multi-Topic Research\n\nLet's build a system with four agents:\n\n1. **Tech Researcher** - Researches AI/ML news and trends\n2. **Health Researcher** - Researches recent medical news and trends\n3. **Finance Researcher** - Researches finance and fintech news and trends\n4. **Aggregator Agent** - Combines all research findings into a single summary","metadata":{"id":"U37FxKxDBtHE"}},{"cell_type":"code","source":"# Tech Researcher: Focuses on AI and ML trends.\ntech_researcher = Agent(\n    name=\"TechResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research the latest AI/ML trends. Include 3 key developments,\nthe main companies involved, and the potential impact. Keep the report very concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"tech_research\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ tech_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T00:51:39.822932Z","iopub.execute_input":"2025-11-11T00:51:39.823393Z","iopub.status.idle":"2025-11-11T00:51:39.830142Z","shell.execute_reply.started":"2025-11-11T00:51:39.823365Z","shell.execute_reply":"2025-11-11T00:51:39.828959Z"}},"outputs":[{"name":"stdout","text":"‚úÖ tech_researcher created.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Health Researcher: Focuses on medical breakthroughs.\nhealth_researcher = Agent(\n    name=\"HealthResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research recent medical breakthroughs. Include 3 significant advances,\ntheir practical applications, and estimated timelines. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"health_research\",  # The result will be stored with this key.\n)\n\nprint(\"‚úÖ health_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T00:51:52.919174Z","iopub.execute_input":"2025-11-11T00:51:52.919515Z","iopub.status.idle":"2025-11-11T00:51:52.925357Z","shell.execute_reply.started":"2025-11-11T00:51:52.919490Z","shell.execute_reply":"2025-11-11T00:51:52.924380Z"}},"outputs":[{"name":"stdout","text":"‚úÖ health_researcher created.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Finance Researcher: Focuses on fintech trends.\nfinance_researcher = Agent(\n    name=\"FinanceResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research current fintech trends. Include 3 key trends,\ntheir market implications, and the future outlook. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"finance_research\",  # The result will be stored with this key.\n)\n\nprint(\"‚úÖ finance_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T00:51:57.093014Z","iopub.execute_input":"2025-11-11T00:51:57.093460Z","iopub.status.idle":"2025-11-11T00:51:57.100390Z","shell.execute_reply.started":"2025-11-11T00:51:57.093424Z","shell.execute_reply":"2025-11-11T00:51:57.099262Z"}},"outputs":[{"name":"stdout","text":"‚úÖ finance_researcher created.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# The AggregatorAgent runs *after* the parallel step to synthesize the results.\naggregator_agent = Agent(\n    name=\"AggregatorAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # It uses placeholders to inject the outputs from the parallel agents, which are now in the session state.\n    instruction=\"\"\"Combine these three research findings into a single executive summary:\n\n    **Technology Trends:**\n    {tech_research}\n    \n    **Health Breakthroughs:**\n    {health_research}\n    \n    **Finance Innovations:**\n    {finance_research}\n    \n    Your summary should highlight common themes, surprising connections, and the most important key takeaways from all three reports. The final summary should be around 200 words.\"\"\",\n    output_key=\"executive_summary\",  # This will be the final output of the entire system.\n)\n\nprint(\"‚úÖ aggregator_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T00:52:11.803486Z","iopub.execute_input":"2025-11-11T00:52:11.803914Z","iopub.status.idle":"2025-11-11T00:52:11.809957Z","shell.execute_reply.started":"2025-11-11T00:52:11.803884Z","shell.execute_reply":"2025-11-11T00:52:11.808973Z"}},"outputs":[{"name":"stdout","text":"‚úÖ aggregator_agent created.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"\n\nüëâ **Then we bring the agents together under a _parallel agent_, which is itself nested inside of a _sequential agent_.**\n\nThis design ensures that the research agents run first in parallel, then once all of their research is complete, the aggregator agent brings together all of the research findings into a single report:","metadata":{}},{"cell_type":"code","source":"# The ParallelAgent runs all its sub-agents simultaneously.\nparallel_research_team = ParallelAgent(\n    name=\"ParallelResearchTeam\",\n    sub_agents=[tech_researcher, health_researcher, finance_researcher],\n)\n\n# This SequentialAgent defines the high-level workflow: run the parallel team first, then run the aggregator.\nroot_agent = SequentialAgent(\n    name=\"ResearchSystem\",\n    sub_agents=[parallel_research_team, aggregator_agent],\n)\n\nprint(\"‚úÖ Parallel and Sequential Agents created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T00:53:06.882871Z","iopub.execute_input":"2025-11-11T00:53:06.883195Z","iopub.status.idle":"2025-11-11T00:53:06.890347Z","shell.execute_reply.started":"2025-11-11T00:53:06.883171Z","shell.execute_reply":"2025-11-11T00:53:06.889150Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Parallel and Sequential Agents created.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"Let's run the agent and give it a prompt to research the given topics:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Run the daily executive briefing on Tech, Health, and Finance\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T00:54:38.397178Z","iopub.execute_input":"2025-11-11T00:54:38.397486Z","iopub.status.idle":"2025-11-11T00:54:43.991780Z","shell.execute_reply.started":"2025-11-11T00:54:38.397463Z","shell.execute_reply":"2025-11-11T00:54:43.990794Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Run the daily executive briefing on Tech, Health, and Finance\nHealthResearcher > Here's a concise executive briefing on recent breakthroughs:\n\n**Health:** Gene therapy is advancing rapidly, with successful treatments for inherited hearing loss and blindness. CRISPR gene editing shows promise for genetic disorders like sickle cell anemia. In the next 3-5 years, we may see more widespread applications of AI in diagnostics and drug discovery.\n\n**Technology:** Agentic AI, capable of autonomous workflows, is emerging as a key trend. Quantum computing has achieved significant milestones, demonstrating \"quantum advantage\" and posing future cybersecurity challenges. Practical applications of autonomous systems in robotics and digital agents are expanding.\n\n**Finance:** Blockchain is streamlining processes in areas like digital bond issuance and risk decisioning. AI and machine learning are transforming risk assessment and user experience. Digital assets and cryptocurrencies are seeing increased integration into traditional banking services.\nFinanceResearcher > It appears you're looking for a consolidated daily executive briefing across Technology, Health, and Finance. Unfortunately, I cannot generate a live, personalized briefing as these are typically subscription-based services tailored to specific industry needs.\n\nHowever, I can outline key trends and their implications based on recent reports, which would form the basis of such a briefing.\n\n**Key Trends:**\n\n1.  **AI Integration Across Industries:**\n    *   **Market Implications:** Companies are rapidly adopting AI for efficiency, automation, and data analysis. However, a significant gap exists in data architecture readiness, with 84% of organizations needing to overhaul their data strategies before AI can be effectively implemented. This creates opportunities for data infrastructure and AI consulting services.\n    *   **Future Outlook:** Expect a continued surge in AI adoption, but also a focus on foundational data readiness. Companies that invest in robust data architectures will gain a competitive advantage.\n\n2.  **Evolving Healthcare Delivery Models:**\n    *   **Market Implications:** Telehealth's role remains dynamic, with policy shifts impacting access and reimbursement. Value-based care models are showing success, with ACOs saving Medicare billions. There's also a growing interest in \"Food is Medicine\" interventions integrated into healthcare systems to manage chronic diseases.\n    *   **Future Outlook:** Healthcare will likely see a blend of in-person and digital services, with a greater emphasis on preventative care, value-based outcomes, and personalized nutrition interventions.\n\n3.  **Fintech's Deepening Role in Financial Services:**\n    *   **Market Implications:** Fintech continues to innovate, offering specialized services and challenging traditional financial institutions. Trends include embedded finance, the rise of digital assets, and increased focus on personalized financial advice through AI.\n    *   **Future Outlook:** The lines between traditional finance and fintech will continue to blur, with a greater emphasis on seamless digital experiences, data-driven insights, and potentially more accessible, albeit regulated, digital asset markets.\nTechResearcher > **Key AI/ML Trends Shaping 2025**\n\nThe AI and Machine Learning landscape is rapidly evolving, with significant advancements impacting technology, health, and finance. Three key developments include:\n\n1.  **Generative AI and Large Language Models (LLMs):** LLMs like Google's Gemini and OpenAI's ChatGPT are revolutionizing content creation, coding assistance, and conversational AI. Companies such as **Google, OpenAI, and Microsoft** are leading this charge, enabling businesses to automate tasks and enhance user experiences.\n2.  **AI in Healthcare:** AI is transforming diagnostics, personalized medicine, and administrative efficiency. Innovations like AI-powered medical imaging analysis and predictive analytics for disease detection are improving patient outcomes. Major players like **Google (DeepMind)** are contributing to these breakthroughs, alongside numerous healthcare organizations.\n3.  **AI in Finance:** The financial sector is leveraging AI for fraud detection, risk analysis, and personalized customer service. AI algorithms enhance market trend analysis and predictive modeling for investments, with companies like **Citibank** implementing ML for customer retention.\n\n**Main Companies Involved:**\n\nKey companies at the forefront of these trends include **Google, Microsoft, NVIDIA, OpenAI, Amazon, and Anthropic**. These tech giants are not only developing core AI technologies but also providing platforms and tools for widespread adoption across industries.\n\n**Potential Impact:**\n\nThe impact of these AI/ML trends is profound, leading to increased efficiency, enhanced decision-making, and the creation of new possibilities across sectors. However, challenges such as data privacy, ethical considerations, and workforce adaptation remain critical. The widespread adoption of AI is projected to drive significant economic growth and reshape industries, demanding continuous innovation and responsible implementation.\nAggregatorAgent > ## Executive Summary: Cross-Sectoral Innovations Driven by AI and Advanced Technologies\n\n**Key Takeaway:** Artificial Intelligence (AI) is the pervasive force shaping the future across technology, health, and finance, driving efficiency, personalization, and novel applications. While significant advancements are being made, foundational challenges in data readiness and ethical considerations must be addressed for widespread adoption and impact.\n\n**Technology:** Generative AI and Large Language Models (LLMs) are revolutionizing content creation, coding, and conversational interfaces, led by companies like Google, OpenAI, and Microsoft. Emerging trends include agentic AI for autonomous workflows and quantum computing's growing influence, potentially challenging cybersecurity.\n\n**Health:** AI is transforming healthcare through advanced diagnostics, personalized medicine, and drug discovery. Gene therapy and CRISPR gene editing are showing remarkable success in treating genetic disorders. The future points to a blend of digital and in-person care, with a focus on preventative and value-based models.\n\n**Finance:** AI and machine learning are critical for fraud detection, risk assessment, and personalized customer experiences. Blockchain is streamlining processes like digital bond issuance, while digital assets are increasingly integrated into traditional banking. Fintech innovation continues to blur industry lines, emphasizing seamless digital experiences.\n\n**Synergies and Challenges:** A significant common theme is the rapid integration of AI across all sectors. However, a substantial gap in data architecture readiness (84% of organizations) poses a critical bottleneck to effective AI implementation. Ethical considerations, data privacy, and workforce adaptation are paramount challenges that require careful management. The convergence of these advancements promises substantial economic growth and industry transformation.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"üéâ Great! You've seen how parallel agents can dramatically speed up workflows by running independent tasks concurrently.\n\nSo far, all our workflows run from start to finish and then stop. **But what if you need to review and improve an output multiple times?** Next, we'll build a workflow that can loop and refine its own work.","metadata":{}},{"cell_type":"markdown","source":"---\n## ‚û∞ Section 5: Loop Workflows - The Refinement Cycle\n\n**The Problem: 'One-Shot' Quality**\n\nAll the workflows we've seen so far run from start to finish. The `SequentialAgent` and `ParallelAgent` produce their final output and then stop. This 'one-shot' approach isn't good for tasks that require refinement and quality control. What if the first draft of our story is bad? We have no way to review it and ask for a rewrite.\n\n**The Solution: Iterative Refinement**\n\nWhen a task needs to be improved through cycles of feedback and revision, you can use a `LoopAgent`. A `LoopAgent` runs a set of sub-agents repeatedly *until a specific condition is met or a maximum number of iterations is reached.* This creates a refinement cycle, allowing the agent system to improve its own work over and over.\n\n**Use Loop when:** Iterative improvement is needed, quality refinement matters, or you need repeated cycles.\n\nTo learn more, check out the documentation related to [loop agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/).\n\n**Architecture: Story Writing & Critique Loop**\n\n<!--\n```mermaid\ngraph TD\n    A[\"Initial Prompt\"] -- > B[\"Writer Agent\"]\n    B -- >|story| C[\"Critic Agent\"]\n    C -- >|critique| D{\"Iteration < Max<br>AND<br>Not Approved?\"}\n    D -- >|Yes| B\n    D -- >|No| E[\"Final Story\"]\n\n    style B fill:#ccffcc\n    style C fill:#ffcccc\n    style D fill:#ffffcc\n```\n-->","metadata":{"id":"fP4I3mvtBtHF"}},{"cell_type":"markdown","source":"<img width=\"250\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/loop-agent.png\" alt=\"Loop Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 5.1 Example: Iterative Story Refinement\n\nLet's build a system with two agents:\n\n1. **Writer Agent** - Writes a draft of a short story\n2. **Critic Agent** - Reviews and critiques the short story to suggest improvements","metadata":{"id":"fP4I3mvtBtHF"}},{"cell_type":"code","source":"# This agent runs ONCE at the beginning to create the first draft.\ninitial_writer_agent = Agent(\n    name=\"InitialWriterAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Based on the user's prompt, write the first draft of a short story (around 100-150 words).\n    Output only the story text, with no introduction or explanation.\"\"\",\n    output_key=\"current_story\",  # Stores the first draft in the state.\n)\n\nprint(\"‚úÖ initial_writer_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T01:16:25.754252Z","iopub.execute_input":"2025-11-11T01:16:25.757412Z","iopub.status.idle":"2025-11-11T01:16:25.771283Z","shell.execute_reply.started":"2025-11-11T01:16:25.757349Z","shell.execute_reply":"2025-11-11T01:16:25.770094Z"}},"outputs":[{"name":"stdout","text":"‚úÖ initial_writer_agent created.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# This agent's only job is to provide feedback or the approval signal. It has no tools.\ncritic_agent = Agent(\n    name=\"CriticAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a constructive story critic. Review the story provided below.\n    Story: {current_story}\n    \n    Evaluate the story's plot, characters, and pacing.\n    - If the story is well-written and complete, you MUST respond with the exact phrase: \"APPROVED\"\n    - Otherwise, provide 2-3 specific, actionable suggestions for improvement.\"\"\",\n    output_key=\"critique\",  # Stores the feedback in the state.\n)\n\nprint(\"‚úÖ critic_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T01:16:43.848973Z","iopub.execute_input":"2025-11-11T01:16:43.849294Z","iopub.status.idle":"2025-11-11T01:16:43.855518Z","shell.execute_reply.started":"2025-11-11T01:16:43.849271Z","shell.execute_reply":"2025-11-11T01:16:43.854392Z"}},"outputs":[{"name":"stdout","text":"‚úÖ critic_agent created.\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"Now, we need a way for the loop to actually stop based on the critic's feedback. The `LoopAgent` itself doesn't automatically know that \"APPROVED\" means \"stop.\"\n\nWe need an agent to give it an explicit signal to terminate the loop.\n\nWe do this in two parts:\n\n1. A simple Python function that the `LoopAgent` understands as an \"exit\" signal.\n2. An agent that can call that function when the right condition is met.\n\nFirst, you'll define the `exit_loop` function:","metadata":{}},{"cell_type":"code","source":"# This is the function that the RefinerAgent will call to exit the loop.\ndef exit_loop():\n    \"\"\"Call this function ONLY when the critique is 'APPROVED', indicating the story is finished and no more changes are needed.\"\"\"\n    return {\"status\": \"approved\", \"message\": \"Story approved. Exiting refinement loop.\"}\n\n\nprint(\"‚úÖ exit_loop function created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T01:17:34.921369Z","iopub.execute_input":"2025-11-11T01:17:34.922147Z","iopub.status.idle":"2025-11-11T01:17:34.928473Z","shell.execute_reply.started":"2025-11-11T01:17:34.922112Z","shell.execute_reply":"2025-11-11T01:17:34.927288Z"}},"outputs":[{"name":"stdout","text":"‚úÖ exit_loop function created.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"To let an agent call this Python function, we wrap it in a `FunctionTool`. Then, we create a `RefinerAgent` that has this tool.\n\nüëâ **Notice its instructions:** this agent is the \"brain\" of the loop. It reads the `{critique}` from the `CriticAgent` and decides whether to (1) call the `exit_loop` tool or (2) rewrite the story.","metadata":{}},{"cell_type":"code","source":"# This agent refines the story based on critique OR calls the exit_loop function.\nrefiner_agent = Agent(\n    name=\"RefinerAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a story refiner. You have a story draft and critique.\n    \n    Story Draft: {current_story}\n    Critique: {critique}\n    \n    Your task is to analyze the critique.\n    - IF the critique is EXACTLY \"APPROVED\", you MUST call the `exit_loop` function and nothing else.\n    - OTHERWISE, rewrite the story draft to fully incorporate the feedback from the critique.\"\"\",\n    output_key=\"current_story\",  # It overwrites the story with the new, refined version.\n    tools=[\n        FunctionTool(exit_loop)\n    ],  # The tool is now correctly initialized with the function reference.\n)\n\nprint(\"‚úÖ refiner_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T01:19:28.550642Z","iopub.execute_input":"2025-11-11T01:19:28.551445Z","iopub.status.idle":"2025-11-11T01:19:28.561385Z","shell.execute_reply.started":"2025-11-11T01:19:28.551393Z","shell.execute_reply":"2025-11-11T01:19:28.560053Z"}},"outputs":[{"name":"stdout","text":"‚úÖ refiner_agent created.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"Then we bring the agents together under a loop agent, which is itself nested inside of a sequential agent.\n\nThis design ensures that the system first produces an initial story draft, then the refinement loop runs up to the specified number of `max_iterations`:","metadata":{}},{"cell_type":"code","source":"# The LoopAgent contains the agents that will run repeatedly: Critic -> Refiner.\nstory_refinement_loop = LoopAgent(\n    name=\"StoryRefinementLoop\",\n    sub_agents=[critic_agent, refiner_agent],\n    max_iterations=2,  # Prevents infinite loops\n)\n\n# The root agent is a SequentialAgent that defines the overall workflow: Initial Write -> Refinement Loop.\nroot_agent = SequentialAgent(\n    name=\"StoryPipeline\",\n    sub_agents=[initial_writer_agent, story_refinement_loop],\n)\n\nprint(\"‚úÖ Loop and Sequential Agents created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T01:20:33.634527Z","iopub.execute_input":"2025-11-11T01:20:33.634927Z","iopub.status.idle":"2025-11-11T01:20:33.642297Z","shell.execute_reply.started":"2025-11-11T01:20:33.634901Z","shell.execute_reply":"2025-11-11T01:20:33.641258Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Loop and Sequential Agents created.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"Let's run the agent and give it a topic to write a short story about:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Write a short story about a lighthouse keeper who discovers a mysterious, glowing map\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T01:20:51.291303Z","iopub.execute_input":"2025-11-11T01:20:51.291657Z","iopub.status.idle":"2025-11-11T01:20:58.307078Z","shell.execute_reply.started":"2025-11-11T01:20:51.291624Z","shell.execute_reply":"2025-11-11T01:20:58.305949Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Write a short story about a lighthouse keeper who discovers a mysterious, glowing map\nInitialWriterAgent > Elias polished the lantern glass, its familiar scent of oil and brine a comfort in the vast, lonely dark. The beam swept its lonely circle across the churning sea, a solitary eye against the encroaching night. Tonight, however, was different. A faint, pulsing light, not of the sea or the stars, had caught his attention. It emanated from a small, barnacle-encrusted chest, wedged between jagged rocks at the tide's lowest ebb.\n\nWith a creak of his old boots, Elias descended the worn steps. Inside the chest, nestled on a bed of damp, decaying seaweed, lay a map. Not of parchment, but of something akin to woven moonlight, it shimmered with an internal luminescence. Strange, intricate symbols pulsed like tiny stars, hinting at depths and distances he'd never charted. His heart, usually as steady as the tide, began to thrum with an unknown rhythm.\nCriticAgent > This is a promising start to a mystery! Here are a few suggestions to make it even stronger:\n\n1.  **Flesh out Elias's personality and current emotional state.** While the text mentions his heart thrumming with an unknown rhythm, we could learn more about Elias *before* this discovery. Is he lonely, bored, yearning for adventure, or content with his solitary life? A brief hint at his baseline emotional state would make the impact of the map's discovery more profound. For example, you could add a sentence early on like, \"Years of solitude had carved deep lines into his face, but also a quiet contentment,\" before introducing the anomaly.\n\n2.  **Enhance the sensory details of the map.** You've done a great job with \"woven moonlight\" and \"pulsed like tiny stars.\" Consider adding another sense, perhaps touch or even sound. Does the map feel cool or warm to the touch? Does it emit a faint hum or whisper? This could add another layer of intrigue and make the map feel even more otherworldly.\n\n3.  **Create more immediate tension or a hint of what's to come.** The discovery is exciting, but what are the immediate implications? Is there a sense of urgency about the map? Does Elias feel drawn to it in a way that overrides his usual caution? Consider adding a subtle hint about the potential danger or the immense power of what he's found. For example, the symbols could momentarily flicker, or Elias might feel a strange pull towards a specific direction on the map.\nRefinerAgent > Elias polished the lantern glass, its familiar scent of oil and brine a comfort in the vast, lonely dark. Years of solitude had carved deep lines into his face, but also a quiet contentment, a steady rhythm in his days as predictable as the tides. The beam swept its lonely circle across the churning sea, a solitary eye against the encroaching night. Tonight, however, was different. A faint, pulsing light, not of the sea or the stars, had caught his attention. It emanated from a small, barnacle-encrusted chest, wedged between jagged rocks at the tide's lowest ebb.\n\nWith a creak of his old boots, Elias descended the worn steps. The air grew heavy with the smell of salt and decay as he reached the chest. He pried it open, revealing a map nestled on a bed of damp, decaying seaweed. It wasn't parchment, but something akin to woven moonlight, cool and smooth to the touch, shimmering with an internal luminescence. Strange, intricate symbols pulsed like tiny stars, and as Elias leaned closer, he could almost hear a faint, ethereal hum emanating from its depths. The symbols seemed to writhe, coalescing into a single, insistent arrow that pointed not towards any known sea, but towards an uncharted void. His heart, usually as steady as the tide, began to thrum with an unknown rhythm, a silent question echoing in the sudden stillness of the night. He felt an inexplicable pull, a dangerous curiosity that threatened to unravel the quiet contentment of his solitary life.\nCriticAgent > APPROVED\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"You've now implemented a loop agent, creating a sophisticated system that can iteratively review and improve its own output. This is a key pattern for ensuring high-quality results.\n\nYou now have a complete toolkit of workflow patterns. Let's put it all together and review how to choose the right one for your use case.","metadata":{}},{"cell_type":"markdown","source":"--- \n## Section 6: Summary - Choosing the Right Pattern\n\n### Decision Tree: Which Workflow Pattern?\n\n<!--\n```mermaid\ngraph TD\n    A{\"What kind of workflow do you need?\"} -- > B[\"Fixed Pipeline<br>(A ‚Üí B ‚Üí C)\"];\n    A -- > C[\"Concurrent Tasks<br>(Run A, B, C all at once)\"];\n    A -- > D[\"Iterative Refinement<br>(A ‚áÜ B)\"];\n    A -- > E[\"Dynamic Decisions<br>(Let the LLM decide what to do)\"];\n\n    B -- > B_S[\"Use <b>SequentialAgent</b>\"];\n    C -- > C_S[\"Use <b>ParallelAgent</b>\"];\n    D -- > D_S[\"Use <b>LoopAgent</b>\"];\n    E -- > E_S[\"Use <b>LLM Orchestrator</b><br>(Agent with other agents as tools)\"];\n\n    style B_S fill:#f9f,stroke:#333,stroke-width:2px\n    style C_S fill:#ccf,stroke:#333,stroke-width:2px\n    style D_S fill:#cff,stroke:#333,stroke-width:2px\n    style E_S fill:#cfc,stroke:#333,stroke-width:2px\n```\n-->","metadata":{"id":"-CKnXSHWBtHF"}},{"cell_type":"markdown","source":"<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/agent-decision-tree.png\" alt=\"Agent Decision Tree\" />","metadata":{}},{"cell_type":"markdown","source":"### Quick Reference Table\n\n| Pattern | When to Use | Example | Key Feature |\n|---------|-------------|---------|-------------|\n| **LLM-based (sub_agents)** | Dynamic orchestration needed | Research + Summarize | LLM decides what to call |\n| **Sequential** | Order matters, linear pipeline | Outline ‚Üí Write ‚Üí Edit | Deterministic order |\n| **Parallel** | Independent tasks, speed matters | Multi-topic research | Concurrent execution |\n| **Loop** | Iterative improvement needed | Writer + Critic refinement | Repeated cycles |","metadata":{"id":"-CKnXSHWBtHF","jp-MarkdownHeadingCollapsed":true}},{"cell_type":"markdown","source":"---\n\n## ‚úÖ Congratulations! You're Now an Agent Orchestrator\n\nIn this notebook, you made the leap from a single agent to a **multi-agent system**.\n\nYou saw **why** a team of specialists is easier to build and debug than one \"do-it-all\" agent. Most importantly, you learned how to be the **director** of that team.\n\nYou used `SequentialAgent`, `ParallelAgent`, and `LoopAgent` to create deterministic workflows, and you even used an LLM as a 'manager' to make dynamic decisions. You also mastered the \"plumbing\" by using `output_key` to pass state between agents and make them collaborative.\n\n**‚ÑπÔ∏è Note: No submission required!**\n\nThis notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n\n### üìö Learn More\n\nRefer to the following documentation to learn more:\n\n- [Agents in ADK](https://google.github.io/adk-docs/agents/)\n- [Sequential Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/)\n- [Parallel Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/)\n- [Loop Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/)\n- [Custom Agents in ADK](https://google.github.io/adk-docs/agents/custom-agents/)\n\n### üéØ Next Steps\n\nReady for the next challenge? Stay tuned for Day 2 notebooks where we'll learn how to create **Custom Functions, use MCP Tools** and manage **Long-Running operations!**","metadata":{}},{"cell_type":"markdown","source":"---\n\n| Authors |\n| --- |\n| [Kristopher Overholt](https://www.linkedin.com/in/koverholt) |","metadata":{}}]}